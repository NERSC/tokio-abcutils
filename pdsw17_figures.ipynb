{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "import pandas\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nersc = abcutils.load_and_synthesize_csv('summaries/edison-summaries_2017-02-14-2018-02-15.csv.gz')\n",
    "df_alcf = abcutils.load_and_synthesize_csv('summaries/mira-summaries_2017-02-14_2018-02-15.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat([df_nersc, df_alcf]).reindex()#.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# PDSW paper applied a few filters\n",
    "filter_criteria = df['coverage_factor_bw'] < 1.2\n",
    "filter_criteria &= (df['_file_system'] != 'mira-fs1') | (df['_jobid'] != 1039807)\n",
    "filter_criteria &= df['_datetime_start'] >= datetime.datetime(2016, 2, 24, 0, 0, 0)\n",
    "filter_criteria &= df['_datetime_end'] <= datetime.datetime(2017, 3, 25, 0, 0, 0)\n",
    "df = df[filter_criteria]\n",
    "\n",
    "print sum(df['_file_system'] != 'mira-fs1')\n",
    "print sum(df['_file_system'] == 'mira-fs1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate how columns can be normalized.  This is the routine used to calculate the fraction of peak performance metric that is calculated for every job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'darshan_agg_perf_by_slowest_posix'\n",
    "group_by_cols = ['darshan_app', '_file_system', 'darshan_fpp_or_ssf_job', 'darshan_read_or_write_job']\n",
    "new_col_base = 'darshan_normalized_perf'\n",
    "\n",
    "# modifies the dataframe in-place; returns nothing\n",
    "abcutils.normalize_column(\n",
    "    dataframe=df,\n",
    "    target_col=target_col,\n",
    "    group_by_cols=group_by_cols,\n",
    "    new_col_base=new_col_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_settings = {\n",
    "    'fontsize': 20,\n",
    "    'darshan_normalized_perf_by_max': {\n",
    "        'output_file': \"perf-boxplots.pdf\",\n",
    "        'ylabel': \"Fraction of\\nPeak Performance\",\n",
    "        'title_pos': [ \n",
    "            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14},\n",
    "            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14}]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots can also be inserted into existing figures with a little more effort.  This can be handy for creating compact publication-ready diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_ROWS = 2\n",
    "NUM_COLS = 2\n",
    "fig, axes = matplotlib.pyplot.subplots(nrows=NUM_ROWS,\n",
    "                                       ncols=NUM_COLS,\n",
    "                                       # sharex causes problems if not all axes contain data\n",
    "                                       #sharex=True,\n",
    "                                       sharey=True)\n",
    "fig.set_size_inches(8,6)\n",
    "\n",
    "SUBPLOT_ARRANGEMENT = {\n",
    "    'scratch1': axes[0, 0],\n",
    "    'scratch2': axes[1, 0],\n",
    "    'scratch3': axes[0, 1],\n",
    "    'mira-fs1': axes[1, 1],\n",
    "}\n",
    "NULL_SUBPLOTS = [\n",
    "]\n",
    "\n",
    "### Draw subplots that contain data\n",
    "for index, fs in enumerate(sorted(SUBPLOT_ARRANGEMENT.keys())):\n",
    "    irow = index / NUM_COLS\n",
    "    ax = SUBPLOT_ARRANGEMENT[fs]\n",
    "    abcutils.plot.grouped_boxplot(df[df[\"_file_system\"] == fs],\n",
    "                                       'darshan_normalized_perf_by_max',\n",
    "                                       ax=ax,\n",
    "                                       fontsize=16)\n",
    "    title = ax.set_title(fs, **(boxplot_settings['darshan_normalized_perf_by_max']['title_pos'][irow]))\n",
    "    title.set_bbox({'color': 'white', 'alpha': 0.5})\n",
    "\n",
    "### Hide subplots that do not contain data\n",
    "for ax in NULL_SUBPLOTS:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "### Set global figure labels \n",
    "fig.suptitle(\"\")\n",
    "fig.text(0.0, 0.5,\n",
    "         boxplot_settings['darshan_normalized_perf_by_max']['ylabel'],\n",
    "         verticalalignment='center',\n",
    "         horizontalalignment='center',\n",
    "         rotation='vertical',\n",
    "         fontsize=boxplot_settings['fontsize'])\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umami Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tokio.analysis.umami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "umami_diagrams = [\n",
    "    # The \"I/O contention\" case study figure\n",
    "    {\n",
    "        'filters': [\n",
    "            df['_file_system'] == 'scratch2',\n",
    "            df['darshan_app'] == 'hacc_io_write',\n",
    "            df['darshan_read_or_write_job'] == 'write',\n",
    "            df['_datetime_start'] > datetime.datetime(2017, 2, 14),\n",
    "            df['_datetime_start'] < datetime.datetime(2017, 3, 3, 0, 0, 0),\n",
    "        ],\n",
    "        'rows': [\n",
    "            'darshan_agg_perf_by_slowest_posix',\n",
    "            'coverage_factor_bw',\n",
    "            'coverage_factor_nodehrs',\n",
    "            'fs_ave_mds_cpu',\n",
    "            'fs_tot_open_ops',\n",
    "            'topology_job_max_radius',\n",
    "        ],\n",
    "        'options': {},\n",
    "    },\n",
    "    # The \"metadata load\" case study figure\n",
    "    {\n",
    "        'filters': [\n",
    "            df['_file_system'] == 'mira-fs1',\n",
    "            df['darshan_app'] == 'vpicio_uni',\n",
    "            df['_datetime_start'] > datetime.datetime(2017, 3, 1, 0, 0, 0),\n",
    "            df['_datetime_start'] < datetime.datetime(2017, 3, 12, 0, 0, 0),\n",
    "        ],\n",
    "        'rows': [\n",
    "            'darshan_agg_perf_by_slowest_posix',\n",
    "            'coverage_factor_bw',\n",
    "            'coverage_factor_ops',\n",
    "            'fs_tot_readdir_ops',\n",
    "        ],\n",
    "        'options': {},\n",
    "    },\n",
    "    # The \"storage capacity\" case study figure\n",
    "    {\n",
    "        'filters': [\n",
    "            df['_file_system'] == 'scratch3',\n",
    "            df['darshan_app'] == 'hacc_io_write',\n",
    "            df['darshan_read_or_write_job'] == 'write',\n",
    "            df['_datetime_start'] > datetime.datetime(2017, 2, 21, 0, 0, 0),\n",
    "            df['_datetime_start'] < datetime.datetime(2017, 3, 15, 0, 0, 0),\n",
    "        ],\n",
    "        'rows': [\n",
    "            'darshan_agg_perf_by_slowest_posix',\n",
    "            'coverage_factor_bw',\n",
    "            'fs_max_oss_cpu',\n",
    "            'fshealth_ost_most_full_pct',\n",
    "        ],\n",
    "        'options': {\n",
    "            'highlight_index': -3,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "pandas.options.display.max_rows = 11\n",
    "filtered_df = abcutils.apply_filters(df, umami_diagrams[0]['filters'], verbose=True)\n",
    "filtered_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for umami_diagram in umami_diagrams:\n",
    "    filtered_df = abcutils.apply_filters(df, umami_diagram['filters'], verbose=True)\n",
    "    fig = abcutils.plot.generate_umami(filtered_df, umami_diagram['rows'], **umami_diagram['options'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
