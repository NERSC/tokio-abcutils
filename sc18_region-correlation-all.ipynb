{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "# matplotlib.rcParams.update({'font.family': 'serif'})\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV\n",
    "\n",
    "This process loads each summary CSV file, creates a few derived metrics, and then merges each system's CSV into a single global dataset that can be sliced and diced by system, benchmark, or any other way.  We are now caching the processed CSV in HDF5 format to speed up initial data ingest at the beginning of each analysis.  Delete the `CACHE_FILE` to re-generate this cache (e.g., when the contents of the CSV are updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df = abcutils.sc18paper.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate a Single Test Platform\n",
    "\n",
    "Look at one combination of (compute system, file system, benchmark) to show what this UMAMI analysis can do.\n",
    "\n",
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST_PLATFORM = 'scratch2@edison'\n",
    "# TEST_PLATFORM = 'cscratch@cori-knl'\n",
    "# TEST_PLATFORM = 'cscratch@cori-haswell'\n",
    "TEST_PLATFORM = 'mira-fs1@mira'\n",
    "\n",
    "# BENCHMARK_ID = 'ior_fpp_write'\n",
    "# BENCHMARK_ID = 'ior_fpp_read'\n",
    "# BENCHMARK_ID = 'dbscan_read_shared_read'\n",
    "# BENCHMARK_ID = 'vpicio_uni_shared_write'\n",
    "# BENCHMARK_ID = 'ior_shared_write'\n",
    "# BENCHMARK_ID = 'ior_shared_read'\n",
    "# BENCHMARK_ID = 'hacc_io_read_fpp_read'\n",
    "# BENCHMARK_ID = 'hacc_io_write_fpp_write'\n",
    "\n",
    "plot_metric = 'darshan_normalized_perf_by_max'\n",
    "delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "# example_df = filtered_df.groupby(by=['_test_platform', '_benchmark_id']).get_group((TEST_PLATFORM, BENCHMARK_ID)).copy()\n",
    "\n",
    "print \"test_platform =\", TEST_PLATFORM\n",
    "# print \"benchmark_id =\", abcutils.CONFIG['benchmark_labels'].get(BENCHMARK_ID, BENCHMARK_ID)\n",
    "print \"plot_metric =\", abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric)\n",
    "print \"date_start =\", abcutils.sc18paper.DATE_START.isoformat()\n",
    "print \"date_end =\", abcutils.sc18paper.DATE_END.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to include in UMAMI renderings and analysis.  Anything that\n",
    "# _might_ affect performance should be included here.\n",
    "umami_rows = [\n",
    "    'darshan_normalized_perf_by_max',\n",
    "    'coverage_factor_bw',\n",
    "#   'coverage_factor_nodehrs',\n",
    "    'coverage_factor_opens',\n",
    "    'coverage_factor_stats',\n",
    "    'coverage_factor_ops',\n",
    "    'fs_ave_mds_cpu',\n",
    "#   'fs_tot_metadata_ops',\n",
    "    'fs_ave_oss_cpu',\n",
    "#   'fs_tot_open_ops',\n",
    "    'fshealth_ost_most_full_pct',\n",
    "    'fshealth_ost_overloaded_oss_count',\n",
    "#   'jobsdb_concurrent_nodes',\n",
    "    'topology_job_max_radius',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region-defined Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width of simple moving average (SMA) short/long windows\n",
    "SHORT_WINDOW = pandas.Timedelta(days=14)\n",
    "LONG_WINDOW = pandas.Timedelta(days=49)\n",
    "\n",
    "print \"Short window will average over %s at a time\" % SHORT_WINDOW\n",
    "print \"Long window will average over %s at a time\" % LONG_WINDOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate intercepts and centroids from SMAs\n",
    "\n",
    "* **Intercepts** are the place where two SMAs cross each other\n",
    "* **Performance regions** are the data bounded by two intercepts\n",
    "* **Centroids** are the centermost data point in a performance region\n",
    "\n",
    "With this nomenclature, it is possible to also define **centroid regions** which are bounded by two centroids.  These regions capture the transition between two performance regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcutoff = 1.0e-5\n",
    "#pcutoff = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_platform': [],\n",
    "    'region_start': [],\n",
    "    'region_end': [],\n",
    "    'region_start_index': [],\n",
    "    'region_end_index': [],\n",
    "    'metric': [],\n",
    "    'coeff': [],\n",
    "    'pvalue': [],\n",
    "    'region_points': []\n",
    "}\n",
    "identified_regions = []\n",
    "\n",
    "for test_platform in filtered_df['_test_platform'].unique():\n",
    "    print \"Processing\", test_platform\n",
    "    example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))\n",
    "\n",
    "    sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                    plot_metric,\n",
    "                                                    short_window=SHORT_WINDOW,\n",
    "                                                    long_window=LONG_WINDOW)\n",
    "\n",
    "    for region in list(abcutils.features.intercepts_to_region(example_df, sma_centroids)):\n",
    "        x = region[plot_metric].values\n",
    "        base_nan_filter = numpy.isnan(x)\n",
    "        title = \"%s - %s (%d points)\" % (\n",
    "            region.iloc[0]['_datetime_start'],\n",
    "            region.iloc[-1]['_datetime_start'],\n",
    "            len(x[~base_nan_filter])\n",
    "        )\n",
    "        \n",
    "        if len(x[~base_nan_filter]) < 3:\n",
    "            # two points will create a correlation with p-value = 0\n",
    "            continue\n",
    "        \n",
    "        identified = False\n",
    "        for y_label in umami_rows: #example_df.columns: #umami_rows:\n",
    "            if y_label == plot_metric:\n",
    "                continue\n",
    "            y = example_df.loc[region.index][y_label].values\n",
    "            try:\n",
    "                nan_filter = base_nan_filter | numpy.isnan(y)\n",
    "            except TypeError:\n",
    "                # non-numeric; pass\n",
    "                continue\n",
    "            this_x = x[~nan_filter]\n",
    "            this_y = y[~nan_filter]\n",
    "            if len(this_y) > 0:\n",
    "                coeff, pval = scipy.stats.pearsonr(this_x, this_y)\n",
    "                if pval < pcutoff and coeff < 0.9999:\n",
    "                    if not identified:\n",
    "                        print \"new region for %s: %s\" % (test_platform, title)\n",
    "                    results['test_platform'].append(test_platform)\n",
    "                    results['region_start'].append(region.iloc[0]['_datetime_start'])\n",
    "                    results['region_end'].append(region.iloc[-1]['_datetime_start'])\n",
    "                    results['region_start_index'].append(region.index[0])\n",
    "                    results['region_end_index'].append(region.index[-1])\n",
    "                    results['metric'].append(y_label)\n",
    "                    results['coeff'].append(coeff)\n",
    "                    results['pvalue'].append(pval)\n",
    "                    results['region_points'].append(len(x[~base_nan_filter]))\n",
    "#                   fig, ax = matplotlib.pyplot.subplots()\n",
    "#                   ax.scatter(this_x, this_y)\n",
    "#                   ax.set_xlabel(abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric))\n",
    "#                   ax.set_ylabel(abcutils.CONFIG['metric_labels'].get(y_label, y_label).replace(' (', '\\n('))\n",
    "#                   ax.grid()\n",
    "#                   fit = scipy.stats.linregress(this_x, this_y)\n",
    "#                   ax.set_xlim(0, 1)\n",
    "#                   ax.plot(ax.get_xticks(),\n",
    "#                           [fit.slope * xi + fit.intercept for xi in ax.get_xticks()],\n",
    "#                           color='C2',\n",
    "#                          linewidth=3)\n",
    "                    print \"    Fit for %20s: R = %8.4f, p = %12.4e\" % (y_label, coeff, pval)\n",
    "#                   print \"    Coefficient: %12.4f\" % coeff\n",
    "#                   print \"    p-value:     %12.4e\" % pval\n",
    "#                   print \"    Slope:       %12.4f\" % fit.slope\n",
    "#                   print \"    Rval:        %12.4e\" % fit.rvalue\n",
    "                    print\n",
    "                    identified = True\n",
    "\n",
    "        # Keep track of regions that have known root causes\n",
    "        if identified:\n",
    "            identified_regions.append(region)\n",
    "\n",
    "results_df = pandas.DataFrame.from_dict(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars = []\n",
    "\n",
    "test_platform_group = results_df.groupby('test_platform')\n",
    "for test_platform in test_platform_group.groups:\n",
    "    metric_group = test_platform_group.get_group(test_platform).groupby('metric')\n",
    "    for metric in metric_group.groups:\n",
    "        coeffs = metric_group.get_group(metric)['coeff']\n",
    "        pvals = metric_group.get_group(metric)['pvalue']\n",
    "        print \"%20s %30s pos: %2d (R=%8.4f), neg: %2d (R=%8.4f), p: %12.4e\" % (test_platform,\n",
    "                                                metric, \n",
    "                                                coeffs[coeffs > 0].count(),\n",
    "                                                coeffs[coeffs > 0].mean(),\n",
    "                                                coeffs[coeffs < 0].count(),\n",
    "                                                coeffs[coeffs < 0].mean(),\n",
    "                                                pvals.mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newxlabel(oldlabel):\n",
    "    if '@' in oldlabel:\n",
    "        fs, sys = oldlabel.split('@', 1)\n",
    "        fs = fs.lstrip('(')\n",
    "        sys = sys.rstrip('),')\n",
    "        if sys == 'cori-knl':\n",
    "            sys = 'Cori'\n",
    "        else:\n",
    "            sys = sys.title()\n",
    "        return \"%s\\n%s\" % ( sys, fs)\n",
    "    else:\n",
    "        return abcutils.CONFIG['umami_rows'].get(oldlabel, oldlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 0.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < 1e-5].groupby(['test_platform', 'metric'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.5]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.1, 1.1)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-20.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "x_regions.append(x_offsets[-1] + 0.5 * (1.0 + XPAD))\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.2,\n",
    "            newxlabel(x_region_names[iregion-1]),\n",
    "            fontsize=16,\n",
    "            ha='center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 1.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < 1e-5].groupby(['metric', 'test_platform'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.0]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.1, 1.1)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    if len(group_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "#       region_end = x_offsets[-1] + 1.0 * (XPAD)\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "#       x_offsets.append(region_end + 1.0)\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-20.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "\n",
    "\n",
    "x_regions.append(x_offsets[-1] + 1.0 * (XPAD))\n",
    "x_offsets.append(x_regions[-1] + 1.0)\n",
    "#x_regions.append(x_offsets[-1] + 0.5 * (1.0 + XPAD))\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels([x.replace('\\n', ' ') for x in x_labels], rotation=45, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "# Vertical text\n",
    "#xmin, xmax = ax.set_xlim(xmin, xmax - XPAD / 2)\n",
    "#for iregion in range(1, len(x_regions)):\n",
    "#    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "#    ax.text(x_regions[iregion-1] + width - XPAD / 2,\n",
    "#            -1.05,\n",
    "#            newxlabel(x_region_names[iregion-1]),\n",
    "#            fontsize=16,\n",
    "#            ha='left',\n",
    "#            va='bottom',\n",
    "#            rotation=90)\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD * 0.9)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.2,\n",
    "            newxlabel(x_region_names[iregion-1]).replace(' ', '\\n'),\n",
    "            fontsize=16,\n",
    "            ha='center')\n",
    "fig.savefig(\"figs/trend-correlations.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify source of bimodality in fs_ave_oss_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_platform = 'cscratch@cori-knl'\n",
    "interesting_metric = 'fs_ave_oss_cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_criteria = results_df['metric'] == interesting_metric\n",
    "filter_criteria &= results_df['test_platform'] == test_platform\n",
    "results_df[filter_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                plot_metric,\n",
    "                                                short_window=SHORT_WINDOW,\n",
    "                                                long_window=LONG_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheat_filter = example_df['_benchmark_id'] == 'hacc_io_write_fpp_write'\n",
    "ax = abcutils.plot.sma_overlaps(dataframe=example_df[cheat_filter],\n",
    "                                plot_metric=plot_metric,\n",
    "                                short_window=SHORT_WINDOW,\n",
    "                                long_window=LONG_WINDOW,\n",
    "                                sma_overlaps=sma_centroids[0:0],\n",
    "                                regioncolors=['#00000000', '#00000000'],\n",
    "                                method='value')\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erase the raw data\n",
    "for patch in ax.patches:\n",
    "    if patch.get_width() == 86400:\n",
    "        patch.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax = ax.set_ylim(0, 1)\n",
    "for row in results_df[filter_criteria].itertuples():\n",
    "    start = abcutils.core.pd2epoch(row.region_start)\n",
    "    end = abcutils.core.pd2epoch(row.region_end)\n",
    "    color = '#FF00002A' if row.coeff < 0.0 else '#0000FF2A'\n",
    "    patch = ax.add_patch(matplotlib.patches.Rectangle(\n",
    "        xy=(start, 0.0),\n",
    "        width=(end - start),\n",
    "        height=(ymax - ymin),\n",
    "        facecolor=color))\n",
    "#   ax.plot([start, start], [ymin, ymax], linestyle='--', color=color)\n",
    "#   ax.plot([end, end], [ymin, ymax], linestyle='--', color=color)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().set_size_inches(8, 3)\n",
    "abcutils.plot.fix_xticks_timeseries(ax)\n",
    "ax.set_ylabel(ax.get_ylabel().replace('\\n', ' '))\n",
    "ax.get_lines()[0].set_label(\"$SMA_{short}$\")\n",
    "ax.get_lines()[1].set_label(\"$SMA_{long}$\")\n",
    "ax.legend(loc='lower right', bbox_to_anchor=(1.01, -0.04))\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"figs/%s-bimodal-%s.pdf\" % (test_platform.split('@', 1)[0], interesting_metric.replace('_', ''))\n",
    "print \"Saving to\", output_file\n",
    "fig.savefig(output_file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
