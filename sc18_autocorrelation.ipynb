{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLATFORMS = [\n",
    "    'scratch1@edison',\n",
    "    'scratch2@edison',\n",
    "    'scratch3@edison',\n",
    "    'cscratch@cori-knl',\n",
    "    'cscratch@cori-haswell',\n",
    "    'mira-fs1@mira'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV\n",
    "\n",
    "This process loads each summary CSV file, creates a few derived metrics, and then merges each system's CSV into a single global dataset that can be sliced and diced by system, benchmark, or any other way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.concat([abcutils.load_and_synthesize_csv('summaries/edison-summaries_2017-02-14-2018-02-28.csv', system='edison'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/cori-summaries_2017-02-14-2018-02-28.csv', system='cori'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/alcf-tokio-results-2_14_17-2_15_18.csv', system='mira')],\n",
    "                   axis='rows')\n",
    "\n",
    "# Reset the index to ensure that there are no degenerate indices in the final dataframe\n",
    "df.index = pandas.Index(data=numpy.arange(len(df)), dtype='int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the signed pair correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2epoch = lambda x: time.mktime(x.to_pydatetime().timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_platform = 'scratch2@edison'\n",
    "#benchmark_id = 'dbscan_read_shared_read'\n",
    "test_platform = 'mira-fs1@mira'\n",
    "benchmark_id = 'hacc_io_write_fpp_write'\n",
    "plot_metric = 'darshan_agg_perf_by_slowest_posix_gibs'\n",
    "date_start = datetime.datetime(2017, 2, 14)\n",
    "date_end = datetime.datetime(2018, 3, 1)\n",
    "group_by = ['_test_platform', '_benchmark_id']\n",
    "\n",
    "filtered_df = df.groupby(by=group_by).get_group((test_platform, benchmark_id))\n",
    "filtered_df = filtered_df[filtered_df['darshan_total_gibs_posix'] > 1.0]\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] < date_end]\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] >= date_start]\n",
    "\n",
    "print \"test_platform =\", test_platform\n",
    "print \"benchmark_id =\", abcutils.CONFIG['benchmark_labels'].get(benchmark_id, benchmark_id)\n",
    "print \"plot_metric =\", abcutils.CONFIG['metric_labels'].get('darshan_normalized_perf_by_max', plot_metric)\n",
    "print \"date_start =\", date_start.isoformat()\n",
    "print \"date_end =\", date_end.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataframe = filtered_df\n",
    "loci = filtered_df\n",
    "\n",
    "full_dataframe = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_old(dataset, loci, xmin, xmax, delta, rcutoff=None, norm=False):\n",
    "    if rcutoff:\n",
    "        width = rcutoff\n",
    "    else:\n",
    "        width = xmax - xmin\n",
    "    num_bins = long(width / delta)\n",
    "    tot_bins = num_bins * 2 - 1\n",
    "    xbins = numpy.hstack((numpy.arange(0, num_bins),\n",
    "                          numpy.arange(- num_bins + 1, 0))) * delta\n",
    "    ybins = numpy.zeros(tot_bins, dtype='float64')\n",
    "    binct = numpy.zeros(tot_bins, dtype='int64')\n",
    "\n",
    "    # convert to dataframe so we can do some fancy indexing\n",
    "    dataset_df = pandas.DataFrame(dataset, columns=['x', 'y'])\n",
    "    for row in dataset_df.itertuples():\n",
    "        x, y = row[1], row[2]\n",
    "        for locus in loci:\n",
    "            # drop self correlation terms\n",
    "            if locus == x:\n",
    "                continue\n",
    "\n",
    "            dx = x - locus\n",
    "            \n",
    "            if rcutoff and abs(dx) > rcutoff:\n",
    "                continue\n",
    "\n",
    "            if abs(dx) > width:\n",
    "                warnings.warn(\"%s, %s: bin out of range\" % x, y)\n",
    "                continue\n",
    "                \n",
    "            x_bin = long(dx / delta)\n",
    "            ybins[x_bin] += y # sum of performance\n",
    "            binct[x_bin] += 1 # sum of measurement count\n",
    "    \n",
    "    # convert results from [0 to N, -N to -1] to [-N to +N]\n",
    "    xbins = numpy.hstack((xbins[num_bins:], xbins[0:num_bins]))\n",
    "    ybins = numpy.hstack((ybins[num_bins:], ybins[0:num_bins]))\n",
    "    binct = numpy.hstack((binct[num_bins:], binct[0:num_bins]))\n",
    "\n",
    "    ybins = numpy.nan_to_num(numpy.divide(ybins, binct)) # mean perf per bin\n",
    "    if norm:    # normalize signal\n",
    "        ybins /= numpy.nanmean(ybins)\n",
    "\n",
    "    return xbins, ybins, binct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(dataset, loci, xmin, xmax, delta, norm=False):\n",
    "    \"\"\"Calculate the pair distribution function for a dataset\n",
    "    \n",
    "    Calculate the autocorrelation of a metric.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list of tuples): list of (x, y) tuples over which the PDF should be calculated\n",
    "        loci (list): x values of interest around which the PDF should be calculated\n",
    "        xmin: minimum value of x in the resulting PDF\n",
    "        xmax: maximum value of x in the resulting PDF\n",
    "        delta: resolution of PDF function expressed in the same units of x\n",
    "        norm: express PDF in terms of fraction performance relative to each locus\n",
    "    Returns:\n",
    "        (xbins, ybins, nbins) where\n",
    "        xbins are the x values of the pair distribution function\n",
    "        ybins are the y values of the pair distribution function\n",
    "        nbins are the number of y values that fell into each bin\n",
    "    \"\"\"\n",
    "    width = xmax - xmin\n",
    "    num_bins = long(width / delta)\n",
    "    xbins = numpy.arange(0, num_bins, dtype='float64') * delta + xmin\n",
    "    ybins = numpy.zeros(num_bins, dtype='float64') + 1.0\n",
    "    nbins = numpy.zeros(num_bins, dtype='int64')\n",
    "\n",
    "    # convert to dataframe so we can do some fancy indexing\n",
    "    dataset_df = pandas.DataFrame(dataset, columns=['x', 'y']).set_index('x')\n",
    "    for locus in loci:\n",
    "        locus_y = dataset_df.loc[locus][0]\n",
    "        for row in dataset_df.itertuples():\n",
    "            x, y = row[0], row[1]\n",
    "\n",
    "            # drop self correlation terms\n",
    "            if locus == x:\n",
    "                continue\n",
    "\n",
    "            dx = x - locus\n",
    "            \n",
    "            if abs(dx) > width:\n",
    "                continue\n",
    "                \n",
    "            x_bin = long(dx / delta) # how many bins away from zero\n",
    "            x_bin -= long(xbins[0] / delta)\n",
    "            \n",
    "            if norm:    # normalize signal\n",
    "                dataset_df\n",
    "                y_val = y / locus_y\n",
    "#               if y_val < 0.5 or y_val > 2.0:\n",
    "#                   print datetime.datetime.fromtimestamp(locus), x_bin, y_val\n",
    "            else:\n",
    "                y_val = y\n",
    "\n",
    "            if x_bin < ybins.shape[0] and x_bin >= 0:\n",
    "                ybins[x_bin] *= y_val # product of performance\n",
    "                nbins[x_bin] += 1 # sum of measurement count\n",
    "\n",
    "#   ybins = numpy.nan_to_num(numpy.divide(ybins, nbins)) # arithmetic mean perf per bin\n",
    "    ybins = numpy.nan_to_num(numpy.power(ybins, nbins.astype('float64')**(-1))) # geometric mean perf per bin\n",
    "\n",
    "    return xbins, ybins, nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = sorted([(pd2epoch(x[1]), x[2]) for x in filtered_df[['_datetime_start', plot_metric]].itertuples()], key=lambda x: x[0])\n",
    "delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "loci = [x[0] for x in dataset]\n",
    "\n",
    "xv, yv, ct = pdf(dataset=dataset,\n",
    "                 loci=loci,\n",
    "                 xmin=-0*delta,\n",
    "                 xmax=+300*delta,\n",
    "                 delta=delta,\n",
    "                 norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = matplotlib.pyplot.subplots(nrows=3, ncols=1)\n",
    "fig.set_size_inches(12,8)\n",
    "\n",
    "x_raw = filtered_df['_datetime_start'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "y_raw = filtered_df[plot_metric]\n",
    "\n",
    "ax = axes[0]\n",
    "ax.grid()\n",
    "ax.plot(x_raw,\n",
    "        y_raw,\n",
    "        linestyle='-',\n",
    "        marker='.')\n",
    "ax.set_ylabel(abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric))\n",
    "ax.set_xticklabels([datetime.datetime.fromtimestamp(x).strftime(\"%b %d\") for x in ax.get_xticks()])\n",
    "fig.suptitle(\"%s on %s\" % (abcutils.CONFIG['benchmark_labels'].get(benchmark_id, benchmark_id),\n",
    "                           test_platform))\n",
    "ax = axes[1]\n",
    "ax.plot(xv / 86400, yv, linestyle='-')\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Relative\\nPerformance\")\n",
    "ax.set_xlabel(\"Days\")\n",
    "ax.set_ylim(0.5, 1.5)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(xv / 86400, ct)\n",
    "ax.set_ylabel(\"# Samples\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Global plot parameters\n",
    "plot_metric = 'darshan_agg_perf_by_slowest_posix_gibs'\n",
    "date_start = datetime.datetime(2017, 2, 14)\n",
    "date_end = datetime.datetime(2018, 3, 1)\n",
    "group_by = ['_test_platform', '_benchmark_id']\n",
    "\n",
    "# Determine which plots to generate\n",
    "test_platforms = sorted(df['_test_platform'].unique())\n",
    "benchmark_ids = sorted(df['_benchmark_id'].unique())\n",
    "# benchmark_ids = ['ior_shared_write']\n",
    "\n",
    "# Generate plots\n",
    "for test_platform in test_platforms:\n",
    "    fig, axes = matplotlib.pyplot.subplots(nrows=len(benchmark_ids),\n",
    "                                           ncols=1,\n",
    "                                           sharex=True,\n",
    "#                                          sharey=True,\n",
    "                                          )\n",
    "    fig.set_size_inches(20, 4 * len(benchmark_ids))\n",
    "    axes[-1].set_xlabel(\"Days\")\n",
    "\n",
    "    for index, benchmark_id in enumerate(benchmark_ids):\n",
    "        ax = axes[index]\n",
    "        ax.grid()\n",
    "        ax.set_ylabel(\"Relative Performance\")\n",
    "        ax.set_title(\"%s %s\" % (test_platform, benchmark_id),\n",
    "                    **{'x': 0.01, 'y': 0.02, 'horizontalalignment': 'left'})\n",
    "        try:\n",
    "            filtered_df = df.groupby(by=group_by).get_group((test_platform, benchmark_id))\n",
    "        except KeyError:\n",
    "            continue\n",
    "        filtered_df = filtered_df[filtered_df['_datetime_start'] < date_end]\n",
    "        filtered_df = filtered_df[filtered_df['_datetime_start'] >= date_start]\n",
    "\n",
    "        dataset = sorted([(pd2epoch(x[1]), x[2]) for x in filtered_df[['_datetime_start', plot_metric]].itertuples()], key=lambda x: x[0])\n",
    "        delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "        loci = [x[0] for x in dataset]\n",
    "\n",
    "        xv, yv, ct = pdf(dataset=dataset,\n",
    "                         loci=loci,\n",
    "                         xmin=-300*delta,\n",
    "                         xmax=+300*delta,\n",
    "                         delta=delta,\n",
    "                         norm=True)\n",
    "\n",
    "        ax.plot(xv / 86400, yv, linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
