{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLATFORMS = [\n",
    "    'scratch1@edison',\n",
    "    'scratch2@edison',\n",
    "    'scratch3@edison',\n",
    "    'cscratch@cori-knl',\n",
    "#   'cscratch@cori-haswell',\n",
    "    'mira-fs1@mira'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV\n",
    "\n",
    "This process loads each summary CSV file, creates a few derived metrics, and then merges each system's CSV into a single global dataset that can be sliced and diced by system, benchmark, or any other way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.concat([abcutils.load_and_synthesize_csv('summaries/edison-summaries_2017-02-14-2018-02-28.csv', system='edison'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/cori-summaries_2017-02-14-2018-02-28.csv', system='cori'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/alcf-tokio-results-2_14_17-2_15_18.csv', system='mira')],\n",
    "                   axis='rows')\n",
    "\n",
    "# Reset the index to ensure that there are no degenerate indices in the final dataframe\n",
    "df.index = pandas.Index(data=numpy.arange(len(df)), dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2epoch = lambda x: time.mktime(x.to_pydatetime().timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['_test_platform', '_benchmark_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_platform = 'scratch2@edison'\n",
    "test_platform = 'cscratch@cori-knl'\n",
    "#test_platform = 'mira-fs1@mira'\n",
    "\n",
    "benchmark_id = 'ior_fpp_write'\n",
    "# benchmark_id = 'dbscan_read_shared_read'\n",
    "# benchmark_id = 'ior_shared_write'\n",
    "\n",
    "plot_metric = 'darshan_agg_perf_by_slowest_posix_gibs'\n",
    "date_start = datetime.datetime(2017, 2, 14)\n",
    "date_end = datetime.datetime(2018, 3, 1)\n",
    "group_by = ['_test_platform', '_benchmark_id']\n",
    "delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "filtered_df = df.groupby(by=group_by).get_group((test_platform, benchmark_id))\n",
    "filtered_df = filtered_df[filtered_df['darshan_total_gibs_posix'] > 1.0]\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] < date_end]\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] >= date_start]\n",
    "\n",
    "print \"test_platform =\", test_platform\n",
    "print \"benchmark_id =\", abcutils.CONFIG['benchmark_labels'].get(benchmark_id, benchmark_id)\n",
    "print \"plot_metric =\", abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric)\n",
    "print \"date_start =\", date_start.isoformat()\n",
    "print \"date_end =\", date_end.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width of simple moving average (SMA) short/long windows\n",
    "short_window = 7\n",
    "long_window = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to include in UMAMI renderings\n",
    "umami_rows = [\n",
    "    'darshan_agg_perf_by_slowest_posix',\n",
    "    'coverage_factor_bw',\n",
    "    'coverage_factor_nodehrs',\n",
    "    'fs_ave_mds_cpu',\n",
    "    'fs_tot_open_ops',\n",
    "    'topology_job_max_radius',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Simple Moving Averages (SMAs)\n",
    "\n",
    "Compare a short-window SMA and a long-window SMA and use that to identify points of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_intercepts = abcutils.features.sma_intercepts(filtered_df, plot_metric, short_window, long_window)\n",
    "sma_minmax = abcutils.features.sma_local_minmax(filtered_df, plot_metric, short_window, long_window, min_domain=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify loci and plot them amidst all of the benchmark data for some visual sanity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_df = filtered_df.loc[sma_minmax[~sma_minmax['positive']].index]\n",
    "loci = [pd2epoch(x) for x in loci_df['_datetime_start']]\n",
    "print \"Found %d loci\" % (len(loci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = filtered_df['_datetime_start'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "y_raw = filtered_df[plot_metric]\n",
    "\n",
    "x_low = loci_df['_datetime_start'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "y_low = loci_df[plot_metric]\n",
    "\n",
    "### plot the raw data\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(16, 4)\n",
    "ax.grid()\n",
    "ax.bar(x_raw, y_raw, width=delta, alpha=0.5)\n",
    "ax.bar(x_low, y_low, width=delta, color='red')\n",
    "ax.set_ylabel(abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric).replace(\" \", \"\\n\"))\n",
    "ax.set_xticklabels([datetime.datetime.fromtimestamp(x).strftime(\"%b %d\") for x in ax.get_xticks()])\n",
    "fig.suptitle(\"%s on %s\" % (abcutils.CONFIG['benchmark_labels'].get(benchmark_id, benchmark_id),\n",
    "                           test_platform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate UMAMI Diagrams Around Loci\n",
    "\n",
    "Combine the start/stop points with the loci so that we can generate UMAMI diagrams that range from the loci to the starting boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sma_minmax['minmax'] = True\n",
    "boundary_df = pandas.concat((sma_minmax, sma_intercepts)).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of dataframe views that contain only the data that we want to populate into an UMAMI diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umamis = []\n",
    "\n",
    "prev_row = None\n",
    "for row in boundary_df.itertuples():\n",
    "    if prev_row is not None and row.minmax is True and row.positive is False:\n",
    "        date_filter = filtered_df['_datetime_start'] >= prev_row[1]\n",
    "        date_filter |= filtered_df['_datetime_start'] >= row[1] - datetime.timedelta(days=7)\n",
    "        date_filter &= filtered_df['_datetime_start'] <= row[1]\n",
    "        umamis.append(filtered_df[date_filter])\n",
    "    prev_row = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, umami_df in enumerate(umamis):\n",
    "    print \"Umami %2d will show %d days\" % (index, len(umami_df))\n",
    "    abcutils.plot.generate_umami(umami_df, umami_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
