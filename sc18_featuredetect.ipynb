{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import time\n",
    "import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Analysis Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLATFORMS = [\n",
    "    'scratch1@edison',\n",
    "    'scratch2@edison',\n",
    "    'scratch3@edison',\n",
    "    'cscratch@cori-knl',\n",
    "    'cscratch@cori-haswell',\n",
    "    'mira-fs1@mira'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.concat([abcutils.load_and_synthesize_csv('summaries/edison-summaries_2017-02-14-2017-12-30.csv', system='edison'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/cori-summaries_2017-02-14-2017-12-31.csv', system='cori'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/alcf-tokio-results-2_14_17-2_15_18.csv', system='mira')],\n",
    "                   axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Streaks\n",
    "\n",
    "Find cases where performance monotonically increased or decreased over the course of several consecutive days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"\"\"\n",
    "Valid benchmark_id values:\n",
    "=========================\"\"\"\n",
    "print \"\\n\".join(df['_benchmark_id'].unique())\n",
    "\n",
    "print \"\"\"\n",
    "Valid test_platform values:\n",
    "==========================\"\"\"\n",
    "print \"\\n\".join(df['_test_platform'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_platform = 'cscratch@cori-knl'\n",
    "benchmark_id = 'ior_fpp_read'\n",
    "plot_metric = 'darshan_normalized_perf_by_max'\n",
    "date_start = datetime.datetime(2017, 2, 14)\n",
    "date_end = date_start + datetime.timedelta(days=365)\n",
    "min_streak = 3 # in days by default\n",
    "\n",
    "filtered_df = df.groupby(by=group_by).get_group((test_platform, benchmark_id))\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] < date_end]\n",
    "filtered_df = filtered_df[filtered_df['_datetime_start'] >= date_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(20,4)\n",
    "\n",
    "ax = abcutils.plot.timeseries_boxplot(filtered_df, plot_metric, date_start, date_end, ax=ax)\n",
    "\n",
    "streaks = abcutils.features.find_streaks(filtered_df[plot_metric], min_streak=min_streak)\n",
    "for streak in streaks:\n",
    "    x = [time.mktime((filtered_df.iloc[x]['_datetime_start']).timetuple()) for x in streak[0]]\n",
    "    if streak[1][-1] > streak[1][0]:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    ax.plot(x,\n",
    "            streak[1],\n",
    "            marker='',\n",
    "            linestyle='-',\n",
    "            linewidth=4,\n",
    "            color=color,\n",
    "            markersize=5,\n",
    "            markerfacecolor=color)\n",
    "xlabel = \"Week\"\n",
    "ylabel = \"%s\\n(%s)\" % (abcutils.CONFIG['benchmark_labels'].get(benchmark_id, benchmark_id),\n",
    "                       abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric))\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating during streaks\n",
    "\n",
    "Look for interesting correlations among the filtered data.  First calculate the correlation vectors for each test platform and assemble a dataframe from those correlation vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlations = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    # Start with a single file system worth of data\n",
    "    df_to_correlate = df[(df['_test_platform'] == fs) & (df['_benchmark_id'] == benchmark_id)]\n",
    "\n",
    "    # Find streaks from the dataframe\n",
    "    streaks = abcutils.features.find_streaks(df_to_correlate[plot_metric], min_streak=min_streak)\n",
    "    \n",
    "    # Build a filter vector that only returns data from streaks\n",
    "    up_filter = [False] * len(df_to_correlate)\n",
    "    down_filter = [False] * len(df_to_correlate)\n",
    "    for streak in streaks:\n",
    "        if streak[1][-1] > streak[1][0]:\n",
    "            for index in streak[0]:\n",
    "                up_filter[index] = True\n",
    "        else:\n",
    "            for index in streak[0]:\n",
    "                down_filter[index] = True\n",
    "#   streak_filter = numpy.array(up_filter) | numpy.array(down_filter)\n",
    "    streak_filter = numpy.array(down_filter)\n",
    "\n",
    "    # Calculate the correlation data for this vector\n",
    "    correlation = abcutils.correlation.calc_correlation_vector(\n",
    "        df_to_correlate[streak_filter],\n",
    "        correlate_with='darshan_normalized_perf_by_max')\n",
    "    \n",
    "    # rename the columns in this vector to include the file system name\n",
    "    new_cols = {}\n",
    "    for index, col_name in enumerate(correlation.columns):\n",
    "        new_cols[col_name] = \"%s %s\" % (fs, col_name)\n",
    "    correlation.rename(columns=new_cols, inplace=True)\n",
    "    \n",
    "    # join the vector to the previous vectors' dataframe\n",
    "    if correlations is None:\n",
    "        correlations = correlation\n",
    "    else:\n",
    "        correlations = pandas.concat([correlations, correlation], axis='columns')\n",
    "\n",
    "# Only draw metrics that show something interesting\n",
    "confidence_filter = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    subfilter = correlations['%s p-value' % fs] < 1.0e-5\n",
    "    subfilter = (correlations['%s coefficient' % fs] > 0.30) | (correlations['%s coefficient' % fs] < -0.30)\n",
    "    if confidence_filter is None:\n",
    "        confidence_filter = subfilter\n",
    "    else:\n",
    "        confidence_filter |= subfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the actual table\n",
    "ax = abcutils.plot.correlation_vector_table(\n",
    "    correlations[confidence_filter],\n",
    "    row_name_map=abcutils.CONFIG['metric_labels'])\n",
    "\n",
    "# Set the table width larger if displaying lots of metrics\n",
    "ax.get_figure().set_size_inches(24, 0.4 * len(correlations[confidence_filter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating only the top and bottom quartiles\n",
    "\n",
    "Instead of correlating against areas where performance increased or decreased over a long period of time, we just take the top and/or bottom quartiles and correlate across the worst and/or best observed performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = [ '_test_platform', '_benchmark_id' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_metrics_grouped = df.groupby(by=group_by).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarized_metrics_grouped.loc['scratch1@edison', 'ior_fpp_read']['coverage_factor_bw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['_test_platform', '_benchmark_id']\n",
    "summarized_metrics_grouped = df.groupby(by=group_by).describe()\n",
    "    \n",
    "correlations = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    # Start with a single file system worth of data\n",
    "#   df_to_correlate = df[(df['_test_platform'] == fs) & (df['_benchmark_id'] == benchmark_id)]\n",
    "    df_to_correlate = df[df['_test_platform'] == fs]\n",
    "    \n",
    "    bottom_cutoff = summarized_metrics_grouped.loc[fs, benchmark_id]['darshan_normalized_perf_by_max']['25%']\n",
    "    median_cutoff = summarized_metrics_grouped.loc[fs, benchmark_id]['darshan_normalized_perf_by_max']['25%']\n",
    "    top_cutoff = summarized_metrics_grouped.loc[fs, benchmark_id]['darshan_normalized_perf_by_max']['75%']\n",
    "#   cutoff_filter = (df_to_correlate['darshan_normalized_perf_by_max'] < bottom_cutoff)\n",
    "#   cutoff_filter = (df_to_correlate['darshan_normalized_perf_by_max'] > top_cutoff)\n",
    "    cutoff_filter = (df_to_correlate['darshan_normalized_perf_by_max'] < median_cutoff)\n",
    "\n",
    "\n",
    "    \n",
    "    # Calculate the correlation data for this vector\n",
    "    correlation = abcutils.correlation.calc_correlation_vector(\n",
    "        df_to_correlate[cutoff_filter],\n",
    "        correlate_with='darshan_normalized_perf_by_max')\n",
    "    \n",
    "    # rename the columns in this vector to include the file system name\n",
    "    new_cols = {}\n",
    "    for index, col_name in enumerate(correlation.columns):\n",
    "        new_cols[col_name] = \"%s %s\" % (fs, col_name)\n",
    "    correlation.rename(columns=new_cols, inplace=True)\n",
    "    \n",
    "    # join the vector to the previous vectors' dataframe\n",
    "    if correlations is None:\n",
    "        correlations = correlation\n",
    "    else:\n",
    "        correlations = pandas.concat([correlations, correlation], axis='columns')\n",
    "\n",
    "# Only draw metrics that show something interesting\n",
    "confidence_filter = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    subfilter = correlations['%s p-value' % fs] < 1.0e-5\n",
    "    subfilter = (correlations['%s coefficient' % fs] > 0.30) | (correlations['%s coefficient' % fs] < -0.30)\n",
    "    if confidence_filter is None:\n",
    "        confidence_filter = subfilter\n",
    "    else:\n",
    "        confidence_filter |= subfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the actual table\n",
    "ax = abcutils.plot.correlation_vector_table(\n",
    "    correlations[confidence_filter],\n",
    "    row_name_map=abcutils.CONFIG['metric_labels'])\n",
    "\n",
    "# Set the table width larger if displaying lots of metrics\n",
    "ax.get_figure().set_size_inches(24, 0.4 * len(correlations[confidence_filter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations[confidence_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
