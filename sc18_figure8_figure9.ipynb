{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV\n",
    "\n",
    "This process loads each summary CSV file, creates a few derived metrics, and then merges each system's CSV into a single global dataset that can be sliced and diced by system, benchmark, or any other way.  We are now caching the processed CSV in HDF5 format to speed up initial data ingest at the beginning of each analysis.  Delete the `CACHE_FILE` to re-generate this cache (e.g., when the contents of the CSV are updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = abcutils.sc18paper.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate a Single Test Platform\n",
    "\n",
    "Look at one combination of (compute system, file system, benchmark) to show what this UMAMI analysis can do.\n",
    "\n",
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric = 'darshan_normalized_perf_by_max'\n",
    "delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "print(\"plot_metric =\", abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric))\n",
    "print(\"date_start =\", abcutils.sc18paper.DATE_START.isoformat())\n",
    "print(\"date_end =\", abcutils.sc18paper.DATE_END.isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cutoff indicates how statistically significant a correlation must\n",
    "# be before it is plotted.  Lower p-values are more statistically significant.\n",
    "pcutoff = 1.0e-5\n",
    "print(\"P-value cutoff is\", pcutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to include in UMAMI renderings and analysis.  Anything that\n",
    "# _might_ affect performance should be included here.\n",
    "umami_rows = [\n",
    "    'darshan_normalized_perf_by_max',\n",
    "    'contention_bw',\n",
    "#   'contention_nodehrs',\n",
    "    'contention_opens',\n",
    "    'contention_stats',\n",
    "    'contention_ops',\n",
    "    'fs_ave_mds_cpu',\n",
    "#   'fs_tot_metadata_ops',\n",
    "    'fs_ave_oss_cpu',\n",
    "#   'fs_tot_open_ops',\n",
    "    'fshealth_ost_most_full_pct',\n",
    "    'fshealth_ost_overloaded_oss_count',\n",
    "#   'jobsdb_concurrent_nodes',\n",
    "    'topology_job_max_radius',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region-defined Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width of simple moving average (SMA) short/long windows\n",
    "SHORT_WINDOW = pandas.Timedelta(days=14)\n",
    "LONG_WINDOW = pandas.Timedelta(days=49)\n",
    "\n",
    "print(\"Short window will average over %s at a time\" % SHORT_WINDOW)\n",
    "print(\"Long window will average over %s at a time\" % LONG_WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlations over each divergence region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_platform': [],\n",
    "    'region_start': [],\n",
    "    'region_end': [],\n",
    "    'region_start_index': [],\n",
    "    'region_end_index': [],\n",
    "    'metric': [],\n",
    "    'coeff': [],\n",
    "    'pvalue': [],\n",
    "    'region_points': []\n",
    "}\n",
    "identified_regions = []\n",
    "\n",
    "for test_platform in filtered_df['_test_platform'].unique():\n",
    "    print(\"Processing\", test_platform)\n",
    "    example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))\n",
    "\n",
    "    sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                    plot_metric,\n",
    "                                                    short_window=SHORT_WINDOW,\n",
    "                                                    long_window=LONG_WINDOW)\n",
    "\n",
    "    for region in list(abcutils.features.intercepts_to_region(example_df, sma_centroids)):\n",
    "        x = region[plot_metric].values\n",
    "        base_nan_filter = numpy.isnan(x)\n",
    "        title = \"%s - %s (%d points)\" % (\n",
    "            region.iloc[0]['_datetime_start'],\n",
    "            region.iloc[-1]['_datetime_start'],\n",
    "            len(x[~base_nan_filter])\n",
    "        )\n",
    "        \n",
    "        if len(x[~base_nan_filter]) < 3:\n",
    "            # two points will create a correlation with p-value = 0\n",
    "            continue\n",
    "        \n",
    "        identified = False\n",
    "        for y_label in umami_rows: #example_df.columns: #umami_rows:\n",
    "            if y_label == plot_metric:\n",
    "                continue\n",
    "            y = example_df.loc[region.index][y_label].values\n",
    "            try:\n",
    "                nan_filter = base_nan_filter | numpy.isnan(y)\n",
    "            except TypeError:\n",
    "                # non-numeric; pass\n",
    "                continue\n",
    "            this_x = x[~nan_filter]\n",
    "            this_y = y[~nan_filter]\n",
    "            if len(this_y) > 0:\n",
    "                coeff, pval = scipy.stats.pearsonr(this_x, this_y)\n",
    "                if pval < pcutoff and coeff < 0.9999:\n",
    "                    if not identified:\n",
    "                        print(\"new region for %s: %s\" % (test_platform, title))\n",
    "                    results['test_platform'].append(test_platform)\n",
    "                    results['region_start'].append(region.iloc[0]['_datetime_start'])\n",
    "                    results['region_end'].append(region.iloc[-1]['_datetime_start'])\n",
    "                    results['region_start_index'].append(region.index[0])\n",
    "                    results['region_end_index'].append(region.index[-1])\n",
    "                    results['metric'].append(y_label)\n",
    "                    results['coeff'].append(coeff)\n",
    "                    results['pvalue'].append(pval)\n",
    "                    results['region_points'].append(len(x[~base_nan_filter]))\n",
    "                    identified = True\n",
    "\n",
    "        # Keep track of regions that have known root causes\n",
    "        if identified:\n",
    "            identified_regions.append(region)\n",
    "\n",
    "results_df = pandas.DataFrame.from_dict(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars = []\n",
    "\n",
    "test_platform_group = results_df.groupby('test_platform')\n",
    "for test_platform in test_platform_group.groups:\n",
    "    metric_group = test_platform_group.get_group(test_platform).groupby('metric')\n",
    "    for metric in metric_group.groups:\n",
    "        coeffs = metric_group.get_group(metric)['coeff']\n",
    "        pvals = metric_group.get_group(metric)['pvalue']\n",
    "        print(\"%20s %30s pos: %2d (R=%8.4f), neg: %2d (R=%8.4f), p: %12.4e\" % (test_platform,\n",
    "                                                metric, \n",
    "                                                coeffs[coeffs > 0].count(),\n",
    "                                                coeffs[coeffs > 0].mean(),\n",
    "                                                coeffs[coeffs < 0].count(),\n",
    "                                                coeffs[coeffs < 0].mean(),\n",
    "                                                pvals.mean()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newxlabel(oldlabel):\n",
    "    if '@' in oldlabel:\n",
    "        label = abcutils.CONFIG['platform_labels_public'].get(oldlabel)\n",
    "        if not label:\n",
    "            # dated method for dynamically generating a human-readable label from the fs@host label\n",
    "            fs, sys = oldlabel.split('@', 1)\n",
    "            fs = fs.lstrip('(')\n",
    "            sys = sys.rstrip('),')\n",
    "            if sys == 'cori-knl':\n",
    "                sys = 'Cori'\n",
    "            else:\n",
    "                sys = sys.title()\n",
    "            return \"%s\\n%s\" % ( sys, fs)\n",
    "        else:\n",
    "            return label\n",
    "    else:\n",
    "        return abcutils.CONFIG['umami_rows'].get(oldlabel, oldlabel).replace(\"CF\", \"Contention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 0.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < pcutoff].groupby(['test_platform', 'metric'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.5]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.1, 1.1)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-20.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "x_regions.append(x_offsets[-1] + 0.5 * (1.0 + XPAD))\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.2,\n",
    "            newxlabel(x_region_names[iregion-1]),\n",
    "            fontsize=16,\n",
    "            ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 1.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < pcutoff].groupby(['metric', 'test_platform'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.0]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.0, 1.0)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    if len(group_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-40.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "\n",
    "\n",
    "x_regions.append(x_offsets[-1] + 1.0 * (XPAD))\n",
    "x_offsets.append(x_regions[-1] + 1.0)\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels([x.replace('\\n', ' ') for x in x_labels], rotation=30, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "# Vertical text\n",
    "#xmin, xmax = ax.set_xlim(xmin, xmax - XPAD / 2)\n",
    "#for iregion in range(1, len(x_regions)):\n",
    "#    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "#    ax.text(x_regions[iregion-1] + width - XPAD / 2,\n",
    "#            -1.05,\n",
    "#            newxlabel(x_region_names[iregion-1]),\n",
    "#            fontsize=16,\n",
    "#            ha='left',\n",
    "#            va='bottom',\n",
    "#            rotation=90)\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD * 0.9)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    label = newxlabel(x_region_names[iregion-1]).replace(' ', '\\n')\n",
    "    if label.startswith(\"Data\"):\n",
    "        label = label.replace(\"\\n\", \" \", 1)\n",
    "    label = label.replace(\"File\\nSystem\", \"File System\")\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.0,\n",
    "            label,\n",
    "            fontsize=18,\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "fig.savefig(\"figs/trend-correlations.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 1.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(4, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < pcutoff].groupby(['metric', 'test_platform'])\n",
    "\n",
    "last_metric = None\n",
    "x_offsets = [0.0]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.0, 1.0)\n",
    "for group in grouped_df:\n",
    "    metric, test_platform = group[0]\n",
    "    group_data = grouped_df.get_group((metric, test_platform))\n",
    "    if len(group_data) == 0:\n",
    "        continue\n",
    "    if metric != \"fs_ave_oss_cpu\":\n",
    "        continue\n",
    "    if metric == last_metric or last_metric is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_metric)\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-40.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_metric = metric\n",
    "\n",
    "    x_labels.append(newxlabel(test_platform))\n",
    "\n",
    "\n",
    "x_regions.append(x_offsets[-1] + 1.0 * (XPAD))\n",
    "x_offsets.append(x_regions[-1] + 1.0)\n",
    "x_region_names.append(last_metric)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels([x.replace('\\n', ' ') for x in x_labels], rotation=30, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "# Vertical text\n",
    "#xmin, xmax = ax.set_xlim(xmin, xmax - XPAD / 2)\n",
    "#for iregion in range(1, len(x_regions)):\n",
    "#    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "#    ax.text(x_regions[iregion-1] + width - XPAD / 2,\n",
    "#            -1.05,\n",
    "#            newxlabel(x_region_names[iregion-1]),\n",
    "#            fontsize=16,\n",
    "#            ha='left',\n",
    "#            va='bottom',\n",
    "#            rotation=90)\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD * 0.9)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    label = newxlabel(x_region_names[iregion-1])\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.0,\n",
    "            label,\n",
    "            fontsize=18,\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "fig.savefig(\"figs/trend-correlations-only-cpuload.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also calculate the overall correlation\n",
    "\n",
    "This demonstrates that targeted correlation is superior to trying to correlate with no time-dependent partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results = results_df[results_df['pvalue'] < pcutoff].groupby(['metric', 'test_platform'])\n",
    "for group in grouped_results:\n",
    "    metric, test_platform = group[0]\n",
    "    group_data = grouped_results.get_group((metric, test_platform))\n",
    "    group_raw_data = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))\n",
    "\n",
    "    print(\"\\n===== %s ======\\n\" % test_platform)\n",
    "    for correlated_metric in group_data['metric'].unique():\n",
    "        x = group_raw_data[plot_metric].values\n",
    "        y = group_raw_data[correlated_metric].values\n",
    "        nan_filter = (numpy.isnan(x) | numpy.isnan(y))\n",
    "        x = x[~nan_filter]\n",
    "        y = y[~nan_filter]\n",
    "        coeff, pval = scipy.stats.pearsonr(x, y)\n",
    "        print(\"Global correlation between %s and %s:\\n  coeff:   %12.4f\\n  p-value: %12.4e\" % (\n",
    "            plot_metric,\n",
    "            correlated_metric,\n",
    "            coeff,\n",
    "            pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify source of bimodality in fs_ave_oss_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_platform = 'cscratch@cori-knl'\n",
    "interesting_metric = 'fs_ave_oss_cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_criteria = results_df['metric'] == interesting_metric\n",
    "filter_criteria &= results_df['test_platform'] == test_platform\n",
    "results_df[filter_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                plot_metric,\n",
    "                                                short_window=SHORT_WINDOW,\n",
    "                                                long_window=LONG_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = matplotlib.rcParams['font.size']\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "\n",
    "POS_CORRELATION_COLOR = 'C0'#'#0000FF'#2A'\n",
    "NEG_CORRELATION_COLOR = 'C3'#'#FF0000'#2A'\n",
    "\n",
    "cheat_filter = example_df['_benchmark_id'] == 'hacc_io_write_fpp_write'\n",
    "ax = abcutils.plot.sma_overlaps(dataframe=example_df[cheat_filter],\n",
    "                                plot_metric=plot_metric,\n",
    "                                short_window=SHORT_WINDOW,\n",
    "                                long_window=LONG_WINDOW,\n",
    "                                sma_overlaps=sma_centroids[0:0],\n",
    "                                regioncolors=['#00000000', '#00000000'],\n",
    "                                plotraw=False)\n",
    "\n",
    "# Thicken the lines for presentation mode\n",
    "for line in ax.get_lines():\n",
    "    line.set_linewidth(4.0)\n",
    "\n",
    "# Draw red and blue patches based on negative and positive correlations\n",
    "ymin, ymax = ax.set_ylim(0, 1)\n",
    "for row in results_df[filter_criteria].itertuples():\n",
    "    start = abcutils.core.pd2epoch(row.region_start)\n",
    "    end = abcutils.core.pd2epoch(row.region_end)\n",
    "    color = NEG_CORRELATION_COLOR if row.coeff < 0.0 else POS_CORRELATION_COLOR\n",
    "    patch = ax.add_patch(matplotlib.patches.Rectangle(\n",
    "        xy=(start, 0.0),\n",
    "        width=(end - start),\n",
    "        height=(ymax - ymin),\n",
    "        facecolor=color))\n",
    "\n",
    "# Set legend and figure size\n",
    "ax.get_figure().set_size_inches(8, 5)\n",
    "abcutils.plot.fix_xticks_timeseries(ax,\n",
    "                                    format=\"%b %Y\",\n",
    "                                    criteria=lambda x: x.day == 1 and x.month % 2 == 0)\n",
    "\n",
    "ax.set_ylabel(ax.get_ylabel().replace('\\n', ' '))\n",
    "ax.get_lines()[0].set_label(\"$SMA_{short}$\")\n",
    "ax.get_lines()[1].set_label(\"$SMA_{long}$\")\n",
    "\n",
    "# Draw the legend\n",
    "legend_handlers = [\n",
    "    matplotlib.lines.Line2D([0], [0], color='C1', lw=4),\n",
    "    matplotlib.lines.Line2D([0], [0], color='C2', lw=4),\n",
    "#   matplotlib.lines.Line2D([0], [0], color='black', linestyle='--', lw=2),\n",
    "    matplotlib.patches.Patch(facecolor=NEG_CORRELATION_COLOR),\n",
    "    matplotlib.patches.Patch(facecolor=POS_CORRELATION_COLOR),\n",
    "]\n",
    "legend_labels = [\n",
    "    \"${SMA}_{short}$\",\n",
    "    \"${SMA}_{long}$\",\n",
    "    \"Correlation < 0\",\n",
    "    \"Correlation > 0\"\n",
    "]\n",
    "ax.legend(legend_handlers, legend_labels, labelspacing=0, loc=\"lower right\", framealpha=1.0)\n",
    "\n",
    "#ax.legend(loc='lower right', bbox_to_anchor=(1.01, -0.04))\n",
    "\n",
    "output_file = \"figs/%s-bimodal-%s.pdf\" % (test_platform.split('@', 1)[0], interesting_metric.replace('_', ''))\n",
    "print(\"Saving to\", output_file)\n",
    "ax.get_figure().savefig(output_file, bbox_inches='tight')\n",
    "\n",
    "matplotlib.rcParams['font.size'] = tmp\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
