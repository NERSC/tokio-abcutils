{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV\n",
    "\n",
    "This process loads each summary CSV file, creates a few derived metrics, and then merges each system's CSV into a single global dataset that can be sliced and diced by system, benchmark, or any other way.  We are now caching the processed CSV in HDF5 format to speed up initial data ingest at the beginning of each analysis.  Delete the `CACHE_FILE` to re-generate this cache (e.g., when the contents of the CSV are updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df = abcutils.sc18paper.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate a Single Test Platform\n",
    "\n",
    "Look at one combination of (compute system, file system, benchmark) to show what this UMAMI analysis can do.\n",
    "\n",
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metric = 'darshan_normalized_perf_by_max'\n",
    "delta = datetime.timedelta(days=1).total_seconds()\n",
    "\n",
    "print \"plot_metric =\", abcutils.CONFIG['metric_labels'].get(plot_metric, plot_metric)\n",
    "print \"date_start =\", abcutils.sc18paper.DATE_START.isoformat()\n",
    "print \"date_end =\", abcutils.sc18paper.DATE_END.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cutoff indicates how statistically significant a correlation must\n",
    "# be before it is plotted.  Lower p-values are more statistically significant.\n",
    "pcutoff = 1.0e-5\n",
    "print \"P-value cutoff is\", pcutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to include in UMAMI renderings and analysis.  Anything that\n",
    "# _might_ affect performance should be included here.\n",
    "umami_rows = [\n",
    "    'darshan_normalized_perf_by_max',\n",
    "    'coverage_factor_bw',\n",
    "#   'coverage_factor_nodehrs',\n",
    "    'coverage_factor_opens',\n",
    "    'coverage_factor_stats',\n",
    "    'coverage_factor_ops',\n",
    "    'fs_ave_mds_cpu',\n",
    "#   'fs_tot_metadata_ops',\n",
    "    'fs_ave_oss_cpu',\n",
    "#   'fs_tot_open_ops',\n",
    "    'fshealth_ost_most_full_pct',\n",
    "    'fshealth_ost_overloaded_oss_count',\n",
    "#   'jobsdb_concurrent_nodes',\n",
    "    'topology_job_max_radius',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region-defined Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width of simple moving average (SMA) short/long windows\n",
    "SHORT_WINDOW = pandas.Timedelta(days=14)\n",
    "LONG_WINDOW = pandas.Timedelta(days=49)\n",
    "\n",
    "print \"Short window will average over %s at a time\" % SHORT_WINDOW\n",
    "print \"Long window will average over %s at a time\" % LONG_WINDOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlations over each divergence region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_platform': [],\n",
    "    'region_start': [],\n",
    "    'region_end': [],\n",
    "    'region_start_index': [],\n",
    "    'region_end_index': [],\n",
    "    'metric': [],\n",
    "    'coeff': [],\n",
    "    'pvalue': [],\n",
    "    'region_points': []\n",
    "}\n",
    "identified_regions = []\n",
    "\n",
    "for test_platform in filtered_df['_test_platform'].unique():\n",
    "    print \"Processing\", test_platform\n",
    "    example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))\n",
    "\n",
    "    sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                    plot_metric,\n",
    "                                                    short_window=SHORT_WINDOW,\n",
    "                                                    long_window=LONG_WINDOW)\n",
    "\n",
    "    for region in list(abcutils.features.intercepts_to_region(example_df, sma_centroids)):\n",
    "        x = region[plot_metric].values\n",
    "        base_nan_filter = numpy.isnan(x)\n",
    "        title = \"%s - %s (%d points)\" % (\n",
    "            region.iloc[0]['_datetime_start'],\n",
    "            region.iloc[-1]['_datetime_start'],\n",
    "            len(x[~base_nan_filter])\n",
    "        )\n",
    "        \n",
    "        if len(x[~base_nan_filter]) < 3:\n",
    "            # two points will create a correlation with p-value = 0\n",
    "            continue\n",
    "        \n",
    "        identified = False\n",
    "        for y_label in umami_rows: #example_df.columns: #umami_rows:\n",
    "            if y_label == plot_metric:\n",
    "                continue\n",
    "            y = example_df.loc[region.index][y_label].values\n",
    "            try:\n",
    "                nan_filter = base_nan_filter | numpy.isnan(y)\n",
    "            except TypeError:\n",
    "                # non-numeric; pass\n",
    "                continue\n",
    "            this_x = x[~nan_filter]\n",
    "            this_y = y[~nan_filter]\n",
    "            if len(this_y) > 0:\n",
    "                coeff, pval = scipy.stats.pearsonr(this_x, this_y)\n",
    "                if pval < pcutoff and coeff < 0.9999:\n",
    "                    if not identified:\n",
    "                        print \"new region for %s: %s\" % (test_platform, title)\n",
    "                    results['test_platform'].append(test_platform)\n",
    "                    results['region_start'].append(region.iloc[0]['_datetime_start'])\n",
    "                    results['region_end'].append(region.iloc[-1]['_datetime_start'])\n",
    "                    results['region_start_index'].append(region.index[0])\n",
    "                    results['region_end_index'].append(region.index[-1])\n",
    "                    results['metric'].append(y_label)\n",
    "                    results['coeff'].append(coeff)\n",
    "                    results['pvalue'].append(pval)\n",
    "                    results['region_points'].append(len(x[~base_nan_filter]))\n",
    "                    identified = True\n",
    "\n",
    "        # Keep track of regions that have known root causes\n",
    "        if identified:\n",
    "            identified_regions.append(region)\n",
    "\n",
    "results_df = pandas.DataFrame.from_dict(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars = []\n",
    "\n",
    "test_platform_group = results_df.groupby('test_platform')\n",
    "for test_platform in test_platform_group.groups:\n",
    "    metric_group = test_platform_group.get_group(test_platform).groupby('metric')\n",
    "    for metric in metric_group.groups:\n",
    "        coeffs = metric_group.get_group(metric)['coeff']\n",
    "        pvals = metric_group.get_group(metric)['pvalue']\n",
    "        print \"%20s %30s pos: %2d (R=%8.4f), neg: %2d (R=%8.4f), p: %12.4e\" % (test_platform,\n",
    "                                                metric, \n",
    "                                                coeffs[coeffs > 0].count(),\n",
    "                                                coeffs[coeffs > 0].mean(),\n",
    "                                                coeffs[coeffs < 0].count(),\n",
    "                                                coeffs[coeffs < 0].mean(),\n",
    "                                                pvals.mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newxlabel(oldlabel):\n",
    "    if '@' in oldlabel:\n",
    "        fs, sys = oldlabel.split('@', 1)\n",
    "        fs = fs.lstrip('(')\n",
    "        sys = sys.rstrip('),')\n",
    "        if sys == 'cori-knl':\n",
    "            sys = 'Cori'\n",
    "        else:\n",
    "            sys = sys.title()\n",
    "        return \"%s\\n%s\" % ( sys, fs)\n",
    "    else:\n",
    "        return abcutils.CONFIG['umami_rows'].get(oldlabel, oldlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 0.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < pcutoff].groupby(['test_platform', 'metric'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.5]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.1, 1.1)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-20.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "x_regions.append(x_offsets[-1] + 0.5 * (1.0 + XPAD))\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.2,\n",
    "            newxlabel(x_region_names[iregion-1]),\n",
    "            fontsize=16,\n",
    "            ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPAD = 1.5\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "\n",
    "grouped_df = results_df[results_df['pvalue'] < pcutoff].groupby(['metric', 'test_platform'])\n",
    "\n",
    "last_sys = None\n",
    "x_offsets = [0.0]\n",
    "x_labels = ['']\n",
    "x_regions = [0.0]\n",
    "x_region_names = []\n",
    "ymin, ymax = ax.set_ylim(-1.1, 1.1)\n",
    "for group in grouped_df:\n",
    "    test_platform, metric = group[0]\n",
    "    group_data = grouped_df.get_group((test_platform, metric))\n",
    "    if len(group_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    if test_platform == last_sys or last_sys is None:\n",
    "        x_offsets.append(x_offsets[-1] + 1.0)\n",
    "    else:\n",
    "        region_end = x_offsets[-1] + 0.5 * (1.0 + XPAD)\n",
    "        ax.plot([region_end, region_end], [ymin, ymax], linestyle='-', color='black')\n",
    "        x_regions.append(region_end)\n",
    "        x_region_names.append(last_sys)\n",
    "        x_offsets.append(x_offsets[-1] + (1.0 + XPAD))\n",
    "\n",
    "    ax.scatter([x_offsets[-1]] * len(group_data),\n",
    "            group_data['coeff'].values,\n",
    "            marker='o',\n",
    "            s=-20.0 * numpy.log10(group_data['pvalue']),\n",
    "            facecolors='#00000044')\n",
    "\n",
    "    last_sys = test_platform\n",
    "\n",
    "    x_labels.append(newxlabel(metric))\n",
    "\n",
    "\n",
    "x_regions.append(x_offsets[-1] + 1.0 * (XPAD))\n",
    "x_offsets.append(x_regions[-1] + 1.0)\n",
    "x_region_names.append(last_sys)\n",
    "ax.set_xticks(x_offsets)\n",
    "ax.set_xticklabels([x.replace('\\n', ' ') for x in x_labels], rotation=45, ha='right')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.plot([xmin, xmax], [0, 0], linestyle='-', color='black', linewidth=1)\n",
    "ax.set_yticks(numpy.arange(-1.0, 1.1, 0.2))\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "# Vertical text\n",
    "#xmin, xmax = ax.set_xlim(xmin, xmax - XPAD / 2)\n",
    "#for iregion in range(1, len(x_regions)):\n",
    "#    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "#    ax.text(x_regions[iregion-1] + width - XPAD / 2,\n",
    "#            -1.05,\n",
    "#            newxlabel(x_region_names[iregion-1]),\n",
    "#            fontsize=16,\n",
    "#            ha='left',\n",
    "#            va='bottom',\n",
    "#            rotation=90)\n",
    "\n",
    "xmin, xmax = ax.set_xlim(xmin, xmax - XPAD * 0.9)\n",
    "for iregion in range(1, len(x_regions)):\n",
    "    width = x_regions[iregion] - x_regions[iregion-1]\n",
    "    ax.text(x_regions[iregion-1] + width / 2.0,\n",
    "            1.2,\n",
    "            newxlabel(x_region_names[iregion-1]).replace(' ', '\\n'),\n",
    "            fontsize=16,\n",
    "            ha='center')\n",
    "fig.savefig(\"figs/trend-correlations.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify source of bimodality in fs_ave_oss_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_platform = 'cscratch@cori-knl'\n",
    "interesting_metric = 'fs_ave_oss_cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_criteria = results_df['metric'] == interesting_metric\n",
    "filter_criteria &= results_df['test_platform'] == test_platform\n",
    "results_df[filter_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = filtered_df.groupby(by=['_test_platform']).get_group((test_platform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_centroids = abcutils.features.sma_intercepts(example_df,\n",
    "                                                plot_metric,\n",
    "                                                short_window=SHORT_WINDOW,\n",
    "                                                long_window=LONG_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cheat_filter = example_df['_benchmark_id'] == 'hacc_io_write_fpp_write'\n",
    "ax = abcutils.plot.sma_overlaps(dataframe=example_df[cheat_filter],\n",
    "                                plot_metric=plot_metric,\n",
    "                                short_window=SHORT_WINDOW,\n",
    "                                long_window=LONG_WINDOW,\n",
    "                                sma_overlaps=sma_centroids[0:0],\n",
    "                                regioncolors=['#00000000', '#00000000'],\n",
    "                                method='value')\n",
    "\n",
    "# Erase the raw data\n",
    "for patch in ax.patches:\n",
    "    if patch.get_width() == 86400:\n",
    "        patch.set_visible(False)\n",
    "\n",
    "# Draw red and blue patches based on negative and positive correlations\n",
    "ymin, ymax = ax.set_ylim(0, 1)\n",
    "for row in results_df[filter_criteria].itertuples():\n",
    "    start = abcutils.core.pd2epoch(row.region_start)\n",
    "    end = abcutils.core.pd2epoch(row.region_end)\n",
    "    color = '#FF00002A' if row.coeff < 0.0 else '#0000FF2A'\n",
    "    patch = ax.add_patch(matplotlib.patches.Rectangle(\n",
    "        xy=(start, 0.0),\n",
    "        width=(end - start),\n",
    "        height=(ymax - ymin),\n",
    "        facecolor=color))\n",
    "\n",
    "# Set legend and figure size\n",
    "ax.get_figure().set_size_inches(8, 3)\n",
    "abcutils.plot.fix_xticks_timeseries(ax)\n",
    "ax.set_ylabel(ax.get_ylabel().replace('\\n', ' '))\n",
    "ax.get_lines()[0].set_label(\"$SMA_{short}$\")\n",
    "ax.get_lines()[1].set_label(\"$SMA_{long}$\")\n",
    "ax.legend(loc='lower right', bbox_to_anchor=(1.01, -0.04))\n",
    "\n",
    "output_file = \"figs/%s-bimodal-%s.pdf\" % (test_platform.split('@', 1)[0], interesting_metric.replace('_', ''))\n",
    "print \"Saving to\", output_file\n",
    "ax.get_figure().savefig(output_file, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
