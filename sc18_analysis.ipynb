{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import time\n",
    "import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import abcutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Analysis Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLATFORMS = [ 'scratch1@edison', 'scratch2@edison', 'scratch3@edison', 'cscratch@cori-knl', 'cscratch@cori-haswell', 'mira-fs1@mira' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Synthesize Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.concat([abcutils.load_and_synthesize_csv('summaries/edison-summaries_2017-02-14-2017-12-30.csv', system='edison'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/cori-summaries_2017-02-14-2017-12-31.csv', system='cori'),\n",
    "                    abcutils.load_and_synthesize_csv('summaries/alcf-tokio-results-2_14_17-2_15_18.csv', system='mira')],\n",
    "                   axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First show the most compelling correlations across all data.  This will be messy because it includes all file systems and test conditions, so there are many uncontrolled variables represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pandas.options.display.max_rows = 40\n",
    "\n",
    "correlation = abcutils.correlation.calc_correlation_vector(df, correlate_with='darshan_normalized_perf_by_max')\n",
    "\n",
    "filtered_correlations = abcutils.apply_filters(correlation, [correlation['p-value'] < 1.0e-5], verbose=True)\n",
    "filtered_correlations.sort_values('coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = abcutils.plot.correlation_vector_table(filtered_correlations, row_name_map=abcutils.CONFIG['metric_labels'])\n",
    "ax.get_figure().set_size_inches(4, 0.4 * len(filtered_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now draw the entire correlation table split out by _test platform_--a combination of the file system being tested and the node configuration being used to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlations = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    # generate a single file system's correlation vector\n",
    "    correlation = abcutils.correlation.calc_correlation_vector(\n",
    "        df[df['_test_platform'] == fs],\n",
    "        correlate_with='darshan_normalized_perf_by_max')\n",
    "            \n",
    "    # rename the columns in this vector to include the file system name\n",
    "    new_cols = {}\n",
    "    for index, col_name in enumerate(correlation.columns):\n",
    "        new_cols[col_name] = \"%s %s\" % (fs, col_name)\n",
    "    correlation.rename(columns=new_cols, inplace=True)\n",
    "    \n",
    "    # join the vector to the previous vectors' dataframe\n",
    "    if correlations is None:\n",
    "        correlations = correlation\n",
    "    else:\n",
    "        correlations = pandas.concat([correlations, correlation], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construct filter to show any metric that registered a low p-value for _any_ file system\n",
    "filters = None\n",
    "for fs in TEST_PLATFORMS:\n",
    "    subfilter = correlations['%s p-value' % fs] < 1.0e-5\n",
    "    if filters is None:\n",
    "        filters = subfilter\n",
    "    else:\n",
    "        filters |= subfilter\n",
    "\n",
    "ax = abcutils.plot.correlation_vector_table(\n",
    "    correlations[filters],\n",
    "    row_name_map=abcutils.CONFIG['metric_labels'])\n",
    "\n",
    "# Set the table width larger if displaying lots of metrics\n",
    "ax.get_figure().set_size_inches(20, 0.4 * len(correlations[filters]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_settings = {\n",
    "    'fontsize': 20,\n",
    "    'darshan_normalized_perf_by_max': {\n",
    "        'output_file': \"perf-boxplots.pdf\",\n",
    "        'ylabel': \"Fraction of\\nPeak Performance\",\n",
    "        'title_pos': [ \n",
    "            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14},\n",
    "            {'x': 0.04, 'y': 0.02, 'horizontalalignment': 'left', 'fontsize': 14}]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_ROWS = 1\n",
    "NUM_COLS = 5\n",
    "fig, axes = matplotlib.pyplot.subplots(nrows=NUM_ROWS,\n",
    "                                       ncols=NUM_COLS,\n",
    "                                       # sharex causes problems if not all axes contain data\n",
    "                                       #sharex=True,\n",
    "                                       sharey=True)\n",
    "fig.set_size_inches(20,4)\n",
    "\n",
    "SUBPLOT_ARRANGEMENT = {\n",
    "    'scratch1@edison': axes[0],\n",
    "    'scratch2@edison': axes[1],\n",
    "    'scratch3@edison': axes[2],\n",
    "    'cscratch@cori-knl': axes[3],\n",
    "    'cscratch@cori-haswell': axes[4]\n",
    "}\n",
    "\n",
    "### Draw subplots that contain data\n",
    "for index, fs in enumerate(sorted(SUBPLOT_ARRANGEMENT.keys())):\n",
    "    irow = index / NUM_COLS\n",
    "    ax = SUBPLOT_ARRANGEMENT[fs]\n",
    "    abcutils.plot.grouped_boxplot(df[df[\"_test_platform\"] == fs],\n",
    "                                       'darshan_normalized_perf_by_max',\n",
    "                                       ax=ax,\n",
    "                                       fontsize=16)\n",
    "    title = ax.set_title(fs, **(boxplot_settings['darshan_normalized_perf_by_max']['title_pos'][irow]))\n",
    "    title.set_bbox({'color': 'white', 'alpha': 0.5})\n",
    "\n",
    "### Set global figure labels \n",
    "fig.suptitle(\"\")\n",
    "fig.text(0.0, 0.5,\n",
    "         boxplot_settings['darshan_normalized_perf_by_max']['ylabel'],\n",
    "         verticalalignment='center',\n",
    "         horizontalalignment='center',\n",
    "         rotation='vertical',\n",
    "         fontsize=boxplot_settings['fontsize'])\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Coverage Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_settings = {\n",
    "    'fontsize': 20,\n",
    "    'darshan_normalized_perf_by_max': {\n",
    "        'output_file': \"perf-boxplots.pdf\",\n",
    "        'ylabel': \"Fraction of\\nPeak Performance\",\n",
    "        'title_pos': [ \n",
    "            {'x': 0.04, 'y': 0.90, 'horizontalalignment': 'left', 'fontsize': 14},\n",
    "            {'x': 0.04, 'y': 0.90, 'horizontalalignment': 'left', 'fontsize': 14}]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 1\n",
    "NUM_COLS = len(TEST_PLATFORMS)\n",
    "fig, axes = matplotlib.pyplot.subplots(nrows=NUM_ROWS,\n",
    "                                       ncols=NUM_COLS,\n",
    "                                       # sharex causes problems if not all axes contain data\n",
    "                                       #sharex=True,\n",
    "                                       sharey=True)\n",
    "fig.set_size_inches(20,4)\n",
    "\n",
    "SUBPLOT_ARRANGEMENT = {\n",
    "    'scratch1@edison': axes[0],\n",
    "    'scratch2@edison': axes[1],\n",
    "    'scratch3@edison': axes[2],\n",
    "    'cscratch@cori-knl': axes[3],\n",
    "    'cscratch@cori-haswell': axes[4],\n",
    "    'mira-fs1@mira': axes[5],\n",
    "}\n",
    "\n",
    "### Draw subplots that contain data\n",
    "for index, fs in enumerate(sorted(SUBPLOT_ARRANGEMENT.keys())):\n",
    "    irow = index / NUM_COLS\n",
    "    ax = SUBPLOT_ARRANGEMENT[fs]\n",
    "\n",
    "    y1 = df[df['_test_platform'] == fs]['coverage_factor_bw'].dropna()\n",
    "    y2 = df[df['_test_platform'] == fs]['coverage_factor_nodehrs'].dropna()\n",
    "    common_opts = {\n",
    "        \"width\": 1.0/15.0,\n",
    "        \"bins\": numpy.linspace(0.0, 1.0, 15),\n",
    "        \"alpha\": 0.75,\n",
    "        \"linewidth\": 3.0,\n",
    "    #   \"zorder\": 9,\n",
    "    }\n",
    "\n",
    "    for y, label in [(y1, 'Coverage Factor (BW)')]: #, (y2, 'Coverage Factor (NodeHrs)')]:\n",
    "        ax.hist(y, label=label, **common_opts)\n",
    "\n",
    "    ax.set_title(fs, fontsize=20)\n",
    "    ax.set_xlabel(\"Coverage Factor\", fontsize=16)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "#   ax.legend(fontsize=12)\n",
    "    ax.yaxis.grid()\n",
    "#   ax.set_yscale(\"log\")\n",
    "#   ax.set_ylim([1, 1e4])\n",
    "    ax.xaxis.set_tick_params(labelsize=14)\n",
    "    ax.yaxis.set_tick_params(labelsize=14)\n",
    "    ax.label_outer()\n",
    "\n",
    "    title = ax.set_title(fs, **(histogram_settings['darshan_normalized_perf_by_max']['title_pos'][irow]))\n",
    "    title.set_bbox({'color': 'white', 'alpha': 0.5})\n",
    "\n",
    "### Set global figure labels \n",
    "fig.suptitle(\"\")\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evolution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['benchmark_id'] = df['darshan_app'] + \"_\"  + df['darshan_fpp_or_ssf_job'] + \"_\" + df['darshan_read_or_write_job']\n",
    "df['darshan_agg_perf_by_slowest_posix_gibs'] = df['darshan_agg_perf_by_slowest_posix'] / 1024.0\n",
    "\n",
    "print \"Valid benchmark_id values:\\n\"\n",
    "print \"\\n\".join(df['benchmark_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxplot_data(df, date_start, date_end, date_delta):\n",
    "    def increment_month(date):\n",
    "        now_month = date.month\n",
    "        now_year = date.year\n",
    "        next_month = now_month + 1 if now_month < 12 else 1\n",
    "        next_year = now_year + 1 if now_month == 12 else now_year\n",
    "        return date.replace(year=next_year, month=next_month)\n",
    "\n",
    "    x = []\n",
    "    x_labels = []\n",
    "    y = []\n",
    "    date = date_start\n",
    "\n",
    "    while date < date_end:\n",
    "    #    next_date = increment_month(date)\n",
    "        next_date = date + datetime.timedelta(days=7)\n",
    "        y.append(df[(df['_datetime_start'] >= date) & (df['_datetime_start'] < next_date)][plot_metric])\n",
    "        x.append(time.mktime(date.timetuple()))\n",
    "        x_labels.append(date.strftime(\"%b %d, %Y\"))\n",
    "\n",
    "        date = next_date\n",
    "    return x, y, x_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_boxplot_timeseries(df, date_start, date_end, benchmark_id, plot_metric):\n",
    "    NUM_ROWS = len(TEST_PLATFORMS)\n",
    "    NUM_COLS = 1\n",
    "    fig, axes = matplotlib.pyplot.subplots(nrows=NUM_ROWS,\n",
    "                                           ncols=NUM_COLS,\n",
    "                                           sharex=True)\n",
    "\n",
    "    fig.set_size_inches(16,20)\n",
    "    \n",
    "    plot_metric_labels = {\n",
    "        'darshan_agg_perf_by_slowest_posix_gibs': 'Bandwidth (GiB/s)',\n",
    "        'darshan_normalized_perf_by_max': 'fraction peak performance',\n",
    "    }\n",
    "    benchmark_id_labels = {\n",
    "        'ior_shared_read': 'IOR shared-file read',\n",
    "        'ior_shared_write': 'IOR shared-file write',\n",
    "        'ior_fpp_read': 'IOR file-per-process read',\n",
    "        'ior_fpp_write': 'IOR file-per-process write',\n",
    "        'dbscan_read_shared_read': 'BD-CATS shared-file read',\n",
    "        'vpicio_uni_shared_write': 'VPIC shared-file write',\n",
    "        'hacc_io_read_fpp_read': 'HACC file-per-process read',\n",
    "        'hacc_io_write_fpp_write': 'HACC file-per-process write',\n",
    "    }\n",
    "    date_delta = datetime.timedelta(days=7)\n",
    "    xlabel = \"Week in 2017\"\n",
    "    ylabel = \"%s\\n(%s)\" % (benchmark_id_labels.get(benchmark_id, benchmark_id),\n",
    "                           plot_metric_labels.get(plot_metric, plot_metric))\n",
    "\n",
    "    boxplot_settings = {\n",
    "        'boxprops': {'linewidth': 2},\n",
    "        'medianprops': {'linewidth': 2},\n",
    "        'whiskerprops': {'linewidth': 2},\n",
    "        'capprops': {'linewidth': 2},\n",
    "        'widths': date_delta.total_seconds() * 5 / 7,\n",
    "        'whis': [5, 95],\n",
    "        'showfliers': False,\n",
    "    }\n",
    "\n",
    "    for index, test_platform in enumerate(TEST_PLATFORMS):\n",
    "        df_filter = ((df['_test_platform'] == test_platform) &\n",
    "                    (df['benchmark_id'] == benchmark_id))\n",
    "\n",
    "        ax = axes[index]\n",
    "\n",
    "        x, y, x_labels = generate_boxplot_data(df[df_filter],\n",
    "                                               date_start,\n",
    "                                               date_end,\n",
    "                                               date_delta)\n",
    "\n",
    "        ax.boxplot(y, positions=x, **boxplot_settings)\n",
    "\n",
    "\n",
    "        ax.set_title(test_platform)\n",
    "        fig.suptitle(\"\")\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_ylim(0)\n",
    "        ax.yaxis.grid(True)\n",
    "\n",
    "        title = ax.set_title(test_platform, **({'x': 0.01, 'y': 0.04, 'horizontalalignment': 'left', 'fontsize': 14}))\n",
    "        title.set_bbox({'color': 'white', 'alpha': 0.5})\n",
    "\n",
    "    ### Set global figure labels \n",
    "    axes[-1].set_xlabel(xlabel)\n",
    "    axes[-1].set_xticklabels(x_labels, rotation=90)\n",
    "    fig.suptitle(\"\")\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    output_file = \"%s.png\" % benchmark_id\n",
    "    fig.savefig(output_file, bbox_inches=\"tight\")\n",
    "    print \"Saved to %s\" % output_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "date_start = datetime.datetime(2017, 2, 1)\n",
    "date_end = datetime.datetime(2018, 2, 1)\n",
    "\n",
    "# plot_metric = 'darshan_normalized_perf_by_max'\n",
    "plot_metric = 'darshan_agg_perf_by_slowest_posix_gibs'\n",
    "benchmark_id = 'ior_shared_read'\n",
    "\n",
    "for benchmark_id in 'dbscan_read_shared_read', 'vpicio_uni_shared_write', 'hacc_io_read_fpp_read', 'hacc_io_write_fpp_write', 'ior_shared_read', 'ior_shared_write', 'ior_fpp_read', 'ior_fpp_write':\n",
    "    draw_boxplot_timeseries(df, date_start, date_end, benchmark_id, plot_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umami Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tokio.tools.umami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "umami_diagrams = [\n",
    "    # The \"I/O contention\" case study figure\n",
    "    {\n",
    "        'filters': [\n",
    "            df['_file_system'] == 'scratch2',\n",
    "            df['darshan_app'] == 'hacc_io_write',\n",
    "            df['darshan_read_or_write_job'] == 'write',\n",
    "            df['_datetime_start'] > datetime.datetime(2017, 2, 14),\n",
    "            df['_datetime_start'] < datetime.datetime(2017, 3, 3, 0, 0, 0),\n",
    "        ],\n",
    "        'rows': [\n",
    "            'darshan_agg_perf_by_slowest_posix',\n",
    "            'coverage_factor_bw',\n",
    "            'coverage_factor_nodehrs',\n",
    "            'fs_ave_mds_cpu',\n",
    "            'fs_tot_open_ops',\n",
    "            'topology_job_max_radius',\n",
    "        ],\n",
    "    },\n",
    "    # The \"storage capacity\" case study figure\n",
    "    {\n",
    "        'filters': [\n",
    "            df['_file_system'] == 'scratch3',\n",
    "            df['darshan_app'] == 'hacc_io_write',\n",
    "            df['darshan_read_or_write_job'] == 'write',\n",
    "            df['_datetime_start'] > datetime.datetime(2017, 2, 21, 0, 0, 0),\n",
    "            df['_datetime_start'] < datetime.datetime(2017, 3, 15, 0, 0, 0),\n",
    "        ],\n",
    "        'rows': [\n",
    "            'darshan_agg_perf_by_slowest_posix',\n",
    "            'coverage_factor_bw',\n",
    "            'fs_max_oss_cpu',\n",
    "            'fshealth_ost_most_full_pct',\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "pandas.options.display.max_rows = 11\n",
    "filtered_df = abcutils.apply_filters(df, umami_diagrams[0]['filters'], verbose=True)\n",
    "filtered_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for umami_diagram in umami_diagrams:\n",
    "    filtered_df = abcutils.apply_filters(df, umami_diagram['filters'], verbose=True)\n",
    "    fig = abcutils.plot.generate_umami(filtered_df, umami_diagram['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
